{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n",
    "\n",
    "This assignment covers Canny edge detector and Hough transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1: Canny Edge Detector (85 points)\n",
    "In this part, you are going to implement a Canny edge detector. The Canny edge detection algorithm can be broken down in to five steps:\n",
    "1. Smoothing\n",
    "2. Finding gradients\n",
    "3. Non-maximum suppression\n",
    "4. Double thresholding\n",
    "5. Edge tracking by hysterisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Smoothing (10 points)\n",
    "#### Implementation (5 points)\n",
    "We first smooth the input image by convolving it with a Gaussian kernel. The equation for a Gaussian kernel of size $(2k+1)\\times(2k+1)$ is given by:\n",
    "\n",
    "$$h_{ij}=\\frac{1}{2\\pi\\sigma^2}\\exp{\\Bigl(-\\frac{(i-k)^2+(j-k)^2}{2\\sigma^2}\\Bigr)}, 0\\leq i,j < 2k+1$$\n",
    "\n",
    "Implement **`gaussian_kernel`** in `edge.py` and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import conv, gaussian_kernel\n",
    "\n",
    "# Define 3x3 Gaussian kernel with std = 1\n",
    "kernel = gaussian_kernel(3, 1)\n",
    "kernel_test = np.array(\n",
    "    [[ 0.05854983, 0.09653235, 0.05854983],\n",
    "     [ 0.09653235, 0.15915494, 0.09653235],\n",
    "     [ 0.05854983, 0.09653235, 0.05854983]]\n",
    ")\n",
    "\n",
    "# Test Gaussian kernel\n",
    "if not np.allclose(kernel, kernel_test):\n",
    "    print('Incorrect values! Please check your implementation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement **`conv`** in `edge.py` and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different kernel_size and sigma\n",
    "kernel_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "# Load image\n",
    "img = io.imread('iguana.png', as_gray=True)\n",
    "\n",
    "# Define 5x5 Gaussian kernel with std = sigma\n",
    "kernel = gaussian_kernel(kernel_size, sigma)\n",
    "\n",
    "# Convolve image with kernel to achieve smoothed effect\n",
    "smoothed = conv(img, kernel)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(smoothed)\n",
    "plt.title('Smoothed image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question (5 points)\n",
    "What is the effect of changing kernel_size and sigma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2 Finding gradients (15 points)\n",
    "The gradient of a 2D scalar function $I:\\mathbb{R}^2\\rightarrow{\\mathbb{R}}$ in Cartesian coordinate is defined by:\n",
    "\n",
    "$$\\nabla{I(x,y)}=\\bigl[\\frac{\\partial{I}}{\\partial{x}},\\frac{\\partial{I}}{\\partial{y}}\\bigr],$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{x}}=\\lim_{\\Delta{x}\\to{0}}\\frac{I(x+\\Delta{x},y)-I(x,y)}{\\Delta{x}} \\\\\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{y}}=\\lim_{\\Delta{y}\\to{0}}\\frac{I(x,y+\\Delta{y})-I(x,y)}{\\Delta{y}}.\n",
    "$$\n",
    "\n",
    "In case of images, we can approximate the partial derivatives by taking differences at one pixel intervals:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{x}}\\approx{\\frac{I(x+1,y)-I(x-1,y)}{2}} \\\\\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{y}}\\approx{\\frac{I(x,y+1)-I(x,y-1)}{2}}\n",
    "$$\n",
    "\n",
    "Note that the partial derivatives can be computed by convolving the image $I$ with some appropriate kernels $D_x$ and $D_y$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I}}{\\partial{x}}\\approx{I*D_x}=G_x \\\\\n",
    "\\frac{\\partial{I}}{\\partial{y}}\\approx{I*D_y}=G_y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation (5 points)\n",
    "Find the kernels $D_x$ and $D_y$ and implement **`partial_x`** and **`partial_y`** using `conv` defined in `edge.py`.\n",
    "\n",
    "*-Hint: Remeber that convolution flips the kernel.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import partial_x, partial_y\n",
    "\n",
    "# Test input\n",
    "I = np.array(\n",
    "    [[0, 0, 0],\n",
    "     [0, 1, 0],\n",
    "     [0, 0, 0]]\n",
    ")\n",
    "\n",
    "# Expected outputs\n",
    "I_x_test = np.array(\n",
    "    [[ 0, 0, 0],\n",
    "     [ 0.5, 0, -0.5],\n",
    "     [ 0, 0, 0]]\n",
    ")\n",
    "\n",
    "I_y_test = np.array(\n",
    "    [[ 0, 0.5, 0],\n",
    "     [ 0, 0, 0],\n",
    "     [ 0, -0.5, 0]]\n",
    ")\n",
    "\n",
    "# Compute partial derivatives\n",
    "I_x = partial_x(I)\n",
    "I_y = partial_y(I)\n",
    "\n",
    "# Test correctness of partial_x and partial_y\n",
    "if not np.all(I_x == I_x_test):\n",
    "    print('partial_x incorrect')\n",
    "    \n",
    "if not np.all(I_y == I_y_test):\n",
    "    print('partial_y incorrect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute partial derivatives of smoothed image\n",
    "Gx = partial_x(smoothed)\n",
    "Gy = partial_y(smoothed)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Gx)\n",
    "plt.title('Derivative in x direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Gy)\n",
    "plt.title('Derivative in y direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question (5 points)\n",
    "What is the reason for performing smoothing prior to computing the gradients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation (5 points)\n",
    "Now, we can compute the magnitude and direction of gradient with the two partial derivatives:\n",
    "\n",
    "$$\n",
    "G = \\sqrt{G_{x}^{2}+G_{y}^{2}} \\\\\n",
    "\\Theta = arctan\\bigl(\\frac{G_{y}}{G_{x}}\\bigr)\n",
    "$$\n",
    "\n",
    "Implement **`gradient`** in `edge.py` which takes in an image and outputs $G$ and $\\Theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import gradient\n",
    "\n",
    "G, theta = gradient(smoothed)\n",
    "\n",
    "if not np.all(G >= 0):\n",
    "    print('Magnitude of gradients should be non-negative.')\n",
    "    \n",
    "if not np.all((theta >= 0) * (theta < 360)):\n",
    "    print('Direction of gradients should be in range 0 <= theta < 360')\n",
    "\n",
    "plt.imshow(G)\n",
    "plt.title('Gradient magnitude')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Non-maximum suppression (15 points)\n",
    "You should be able to see that the edges extracted from the gradient of the smoothed image are quite thick and blurry. The purpose of this step is to convert the \"blurred\" edges into \"sharp\" edges. Basically, this is done by preserving all local maxima in the gradient image and discarding everything else. The algorithm is for each pixel (x,y) in the gradient image:\n",
    "1. Round the gradient direction $\\Theta[y,x]$ to the nearest 45 degrees, corresponding to the use of an 8-connected neighbourhood.\n",
    "\n",
    "2. Compare the edge strength of the current pixel with the edge strength of the pixel in the positive and negative gradient directions. For example, if the gradient direction is south (theta=90), compare with the pixels to the north and south.\n",
    "\n",
    "3. If the edge strength of the current pixel is the largest; preserve the value of the edge strength. If not, suppress (i.e. remove) the value.\n",
    "\n",
    "Implement **`non_maximum_suppression`** in `edge.py`.\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import non_maximum_suppression\n",
    "\n",
    "# Test input\n",
    "g = np.array(\n",
    "    [[0.4, 0.5, 0.6],\n",
    "     [0.3, 0.5, 0.7],\n",
    "     [0.4, 0.5, 0.6]]\n",
    ")\n",
    "\n",
    "# Print out non-maximum suppressed output\n",
    "# varying theta\n",
    "for angle in range(0, 180, 45):\n",
    "    #print('Thetas:', angle)\n",
    "    t = np.ones((3, 3)) * angle # Initialize theta\n",
    "    print(non_maximum_suppression(g, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = non_maximum_suppression(G, theta)\n",
    "plt.imshow(nms)\n",
    "plt.title('Non-maximum suppressed')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(nms)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_non_max_suppressed.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(nms - reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "np.amax(nms-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Double Thresholding (20 points)\n",
    "\n",
    "The edge-pixels remaining after the non-maximum suppression step are (still) marked with their strength pixel-by-pixel. Many of these will probably be true edges in the image, but some may be caused by noise or color variations, for instance, due to rough surfaces. The simplest way to discern between these would be to use a threshold, so that only edges stronger that a certain value would be preserved. The Canny edge detection algorithm uses double thresholding. Edge pixels stronger than the high threshold are marked as strong; edge pixels weaker than the low threshold are suppressed and edge pixels between the two thresholds are marked as weak.\n",
    "\n",
    "Implement **`double_thresholding`** in `edge.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import double_thresholding\n",
    "\n",
    "low_threshold = 0.02\n",
    "high_threshold = 0.03\n",
    "\n",
    "strong_edges, weak_edges = double_thresholding(nms, high_threshold, low_threshold)\n",
    "assert(np.sum(strong_edges & weak_edges) == 0)\n",
    "\n",
    "edges=strong_edges * 1.0 + weak_edges * 0.5\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(strong_edges)\n",
    "plt.title('Strong Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(edges)\n",
    "plt.title('Strong+Weak Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Edge tracking (15 points)\n",
    "\n",
    "Strong edges are interpreted as “certain edges”, and can immediately be included in the final edge image. Consider its neighbors iteratively then declare it an 'edge pixel' if it is connected to a 'strong edge pixel' directly or via pixels between Low and High. The logic is of course that noise and other small variations are unlikely to result in a strong edge (with proper adjustment of the threshold levels). Thus strong edges will (almost) only be due to true edges in the original image. The weak edges can either be due to true edges or noise/color variations. The latter type will probably be distributed independently of edges on the entire image, and thus only a small amount will be located adjacent to strong edges. Weak edges due to true edges are much more likely to be connected directly to strong edges.\n",
    "\n",
    "Implement **`link_edges`** in `edge.py`.\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import get_neighbors, link_edges\n",
    "\n",
    "test_strong = np.array(\n",
    "    [[1, 0, 0, 0],\n",
    "     [0, 0, 0, 0],\n",
    "     [0, 0, 0, 0],\n",
    "     [0, 0, 0, 1]],\n",
    "    dtype=np.bool\n",
    ")\n",
    "\n",
    "test_weak = np.array(\n",
    "    [[0, 0, 0, 1],\n",
    "     [0, 1, 0, 0],\n",
    "     [1, 0, 0, 0],\n",
    "     [0, 0, 1, 0]],\n",
    "    dtype=np.bool\n",
    ")\n",
    "\n",
    "test_linked = link_edges(test_strong, test_weak)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_strong)\n",
    "plt.title('Strong edges')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_weak)\n",
    "plt.title('Weak edges')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(test_linked)\n",
    "plt.title('Linked edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = link_edges(strong_edges, weak_edges)\n",
    "\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_edge_tracking.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(edges ^ reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Canny edge detector\n",
    "Implement **`canny`** in `edge.py` using the functions you have implemented so far. Test edge detector with different parameters.\n",
    "\n",
    "Here is an example of the output:\n",
    "\n",
    "![iguana_edges.png](iguana_edges.png)\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import canny\n",
    "\n",
    "# Load image\n",
    "img = io.imread('iguana.png', as_gray=True)\n",
    "\n",
    "# Run Canny edge detector\n",
    "edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n",
    "print (edges.shape)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_canny.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(edges ^ reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Question (10 points)\n",
    "\n",
    "![1.7a.png](1.7a.png)\n",
    "**(a)** Suppose that the Canny edge detector successfully detects an edge in an image. The edge (see the figure above) is then rotated by θ, where the relationship between a point on the original edge $(x, y)$ and a point on the rotated edge $(x', y')$ is defined as\n",
    "\n",
    "$$\n",
    "x'=x\\cos{\\theta}\\\\\n",
    "y'=x\\sin{\\theta}\n",
    "$$\n",
    "\n",
    "Will the rotated edge be detected using the same Canny edge detector? Provide either a mathematical proof or a counter example.\n",
    "\n",
    "*-Hint 1: The detection of an edge by the Canny edge detector depends only on the magnitude of its derivative. The derivative at point (x, y) is determined by its components along the x and y directions. Think about how these magnitudes have changed because of the rotation.* <br>\n",
    "*-Hint 2: You can assume that (x,y) lies on the x-axis, i.e., y = 0. * <br>\n",
    "*-Hint 3: You can also assume that G_x(x, y) = 0. In other words, the gradient which is perpendicular to the direction of the unrotated edge at (x, y) only has a vertical component and thus only consists of G_y(x, y).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** After running the Canny edge detector on an image, you notice that long edges are broken into short segments separated by gaps. In addition, some spurious edges appear. For each of the two thresholds (low and high) used in hysteresis thresholding, explain how you would adjust the threshold (up or down) to address both problems. Assume that a setting exists for the two thresholds that produces the desired result. Briefly explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit: Optimizing Edge Detector\n",
    "One way of evaluating an edge detector is to compare detected edges with manually specified ground truth edges. Here, we use precision, recall and F1 score as evaluation metrics. We provide you 40 images of objects with ground truth edge annotations. Run the code below to compute precision, recall and F1 score over the entire set of images. Then, tweak the parameters of the Canny edge detector to get as high F1 score as possible. You should be able to achieve F1 score higher than 0.31 by carefully setting the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from itertools import product\n",
    "\n",
    "# Define parameters to test\n",
    "sigmas = []\n",
    "highs = []\n",
    "lows = []\n",
    "\n",
    "for sigma, high, low in product(sigmas, highs, lows):\n",
    "\n",
    "    print(\"sigma={}, high={}, low={}\".format(sigma, high, low))\n",
    "    n_detected = 0.0\n",
    "    n_gt = 0.0\n",
    "    n_correct = 0.0\n",
    "\n",
    "    for img_file in listdir('images/objects'):\n",
    "        img = io.imread('images/objects/'+img_file, as_gray=True)\n",
    "        gt = io.imread('images/gt/'+img_file+'.gtf.pgm', as_gray=True)\n",
    "\n",
    "        mask = (gt != 5) # 'don't' care region\n",
    "        gt = (gt == 0) # binary image of GT edges\n",
    "\n",
    "        edges = canny(img, kernel_size=5, sigma=sigma, high=high, low=low)\n",
    "        edges = edges * mask\n",
    "\n",
    "        n_detected += np.sum(edges)\n",
    "        n_gt += np.sum(gt)\n",
    "        n_correct += np.sum(edges * gt)\n",
    "\n",
    "    p_total = n_correct / n_detected\n",
    "    r_total = n_correct / n_gt\n",
    "    f1 = 2 * (p_total * r_total) / (p_total + r_total)\n",
    "    print('Total precision={:.4f}, Total recall={:.4f}'.format(p_total, r_total))\n",
    "    print('F1 score={:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2: Lane Detection (15 points)\n",
    "\n",
    "In this section we will implement a simple lane detection application using Canny edge detector and Hough transform.\n",
    "Here are some example images of how your final lane detector will look like.\n",
    "<img src=\"lane1.png\" width=\"400\">\n",
    "<img src=\"lane2.png\" width=\"400\">\n",
    "\n",
    "The algorithm can broken down into the following steps:\n",
    "1. Detect edges using the Canny edge detector.\n",
    "2. Extract the edges in the region of interest (a triangle covering the bottom corners and the center of the image).\n",
    "3. Run Hough transform to detect lanes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Edge detection\n",
    "Lanes on the roads are usually thin and long lines with bright colors. Our edge detection algorithm by itself should be able to find the lanes pretty well. Run the code cell below to load the example image and detect edges from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import canny\n",
    "\n",
    "# Load image\n",
    "img = io.imread('road.jpg', as_gray=True)\n",
    "\n",
    "# Run Canny edge detector\n",
    "edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extracting region of interest (ROI)\n",
    "We can see that the Canny edge detector could find the edges of the lanes. However, we can also see that there are edges of other objects that we are not interested in. Given the position and orientation of the camera, we know that the lanes will be located in the lower half of the image. The code below defines a binary mask for the ROI and extract the edges within the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = img.shape\n",
    "\n",
    "# Generate mask for ROI (Region of Interest)\n",
    "mask = np.zeros((H, W))\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        if i > (H / W) * j and i > -(H / W) * j + H:\n",
    "            mask[i, j] = 1\n",
    "\n",
    "# Extract edges in ROI\n",
    "roi = edges * mask\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask)\n",
    "plt.title('Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(roi)\n",
    "plt.title('Edges in ROI')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fitting lines using Hough transform (15 points)\n",
    "The output from the edge detector is still a collection of connected points. However, it would be more natural to represent a lane as a line parameterized as $y = ax + b$, with a slope $a$ and y-intercept $b$. We will use Hough transform to find parameterized lines that represent the detected edges.\n",
    "\n",
    "In general, a straight line $y = ax + b$ can be represented as a point $(a, b)$ in the parameter space. This is the parameterization we often use when introducing the Hough transform.  However, this cannot represent vertical lines as the slope parameter will be unbounded. Alternatively, we parameterize a line using $\\theta\\in{[-\\pi, \\pi]}$ and $\\rho\\in{\\mathbb{R}}$ as follows:\n",
    "\n",
    "$$\n",
    "\\rho = x\\cdot{cos\\theta} + y\\cdot{sin\\theta}\n",
    "$$\n",
    "\n",
    "Using this parameterization, we can map every point in $xy$-space to a sine-like line in $\\theta\\rho$-space (or Hough space). We then accumulate the parameterized points in the Hough space and choose points (in Hough space) with highest accumulated values. A point in Hough space then can be transformed back into a line in $xy$-space.\n",
    "\n",
    "*See [notes](http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/HoughTrans_lines_09.pdf) on Hough transform.*\n",
    "\n",
    "Implement **`hough_transform`** in `edge.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edge import hough_transform\n",
    "\n",
    "# Perform Hough transform on the ROI\n",
    "acc, rhos, thetas = hough_transform(roi)\n",
    "\n",
    "# Coordinates for right lane\n",
    "xs_right = []\n",
    "ys_right = []\n",
    "\n",
    "# Coordinates for left lane\n",
    "xs_left = []\n",
    "ys_left = []\n",
    "\n",
    "for i in range(20):\n",
    "    idx = np.argmax(acc)\n",
    "    r_idx = idx // acc.shape[1]\n",
    "    t_idx = idx % acc.shape[1]\n",
    "    acc[r_idx, t_idx] = 0 # Zero out the max value in accumulator\n",
    "\n",
    "    rho = rhos[r_idx]\n",
    "    theta = thetas[t_idx]\n",
    "    \n",
    "    # Transform a point in Hough space to a line in xy-space.\n",
    "    a = - (np.cos(theta)/np.sin(theta)) # slope of the line\n",
    "    b = (rho/np.sin(theta)) # y-intersect of the line\n",
    "\n",
    "    # Break if both right and left lanes are detected\n",
    "    if xs_right and xs_left:\n",
    "        break\n",
    "    \n",
    "    if a < 0: # Left lane\n",
    "        if xs_left:\n",
    "            continue\n",
    "        xs = xs_left\n",
    "        ys = ys_left\n",
    "    else: # Right Lane\n",
    "        if xs_right:\n",
    "            continue\n",
    "        xs = xs_right\n",
    "        ys = ys_right\n",
    "\n",
    "    for x in range(img.shape[1]):\n",
    "        y = a * x + b\n",
    "        if y > img.shape[0] * 0.6 and y < img.shape[0]:\n",
    "            xs.append(x)\n",
    "            ys.append(int(round(y)))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.plot(xs_left, ys_left, linewidth=5.0)\n",
    "plt.plot(xs_right, ys_right, linewidth=5.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: Seam Carving\n",
    "This extra credit section covers seam carving for the purpose of content-aware resizing. The whole seam carving process was covered in lecture, please refer to the slides for more details to the different concepts introduced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from skimage import color\n",
    "\n",
    "from time import time\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Reducing using Seam Carving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, util\n",
    "\n",
    "# Load image\n",
    "img = io.imread('imgs/broadway_tower.jpg')\n",
    "img = util.img_as_float(img)\n",
    "\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy function (5 points)\n",
    "We will now implemented the `energy_function` to compute the energy of the image.  \n",
    "The energy at each pixel is the sum of:\n",
    "- absolute value of the gradient in the $x$ direction\n",
    "- absolute value of the gradient in the $y$ direction\n",
    "\n",
    "\n",
    "The function should take less than 0.1 seconds to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import energy_function\n",
    "\n",
    "test_img = np.array([[1.0, 2.0, 1.5],\n",
    "                     [3.0, 1.0, 2.0],\n",
    "                     [4.0, 0.5, 3.0]])\n",
    "test_img = np.stack([test_img] * 3, axis=2)\n",
    "assert test_img.shape == (3, 3, 3)\n",
    "\n",
    "# Compute energy function\n",
    "test_energy = energy_function(test_img)\n",
    "\n",
    "solution_energy = np.array([[3.0, 1.25,  1.0],\n",
    "                            [3.5, 1.25, 1.75],\n",
    "                            [4.5,  1.0,  3.5]])\n",
    "\n",
    "print(\"Image (channel 0):\")\n",
    "print(test_img[:, :, 0])\n",
    "\n",
    "print(\"Energy:\")\n",
    "print(test_energy)\n",
    "print(\"Solution energy:\")\n",
    "print(solution_energy)\n",
    "\n",
    "assert np.allclose(test_energy, solution_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize your energy function. The expected output is:\n",
    "![imgs/energy_soln.png](imgs/energy_soln.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute energy function\n",
    "start = time()\n",
    "energy = energy_function(img)\n",
    "end = time()\n",
    "\n",
    "print(\"Computing energy function: %f seconds.\" % (end - start))\n",
    "\n",
    "plt.title('Energy')\n",
    "plt.axis('off')\n",
    "plt.imshow(energy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cost (10 points)\n",
    "\n",
    "Now implement the function `compute_cost`.\n",
    "Starting from the energy map, we'll go from the first row of the image to the bottom and compute the minimal cost at each pixel.\n",
    "\n",
    "We'll use dynamic programming to compute the cost line by line starting from the first row.\n",
    "\n",
    "The function should take less than 0.1 seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import compute_cost\n",
    "\n",
    "# Let's first test with a small example\n",
    "\n",
    "test_energy = np.array([[1.0, 2.0, 1.5],\n",
    "                        [3.0, 1.0, 2.0],\n",
    "                        [4.0, 0.5, 3.0]])\n",
    "\n",
    "solution_cost = np.array([[1.0, 2.0, 1.5],\n",
    "                          [4.0, 2.0, 3.5],\n",
    "                          [6.0, 2.5, 5.0]])\n",
    "\n",
    "solution_paths = np.array([[ 0,  0,  0],\n",
    "                           [ 0, -1,  0],\n",
    "                           [ 1,  0, -1]])\n",
    "\n",
    "# Vertical Cost Map\n",
    "vcost, vpaths = compute_cost(_, test_energy, axis=1)  # don't need the first argument for compute_cost\n",
    "\n",
    "print(\"Energy:\")\n",
    "print(test_energy)\n",
    "\n",
    "print(\"Cost:\")\n",
    "print(vcost)\n",
    "print(\"Solution cost:\")\n",
    "print(solution_cost)\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(vpaths)\n",
    "print(\"Solution paths:\")\n",
    "print(solution_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize a map of the vertical and horizontal costs. The expected outputs are:\n",
    "\n",
    "Vertical Cost:\n",
    "![imgs/vertical_cost_soln.png](imgs/vertical_cost_soln.png)\n",
    "\n",
    "Horizontal Cost:\n",
    "![imgs/horizontal_cost_soln.png](imgs/horizontal_cost_soln.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical Cost Map\n",
    "start = time()\n",
    "vcost, _ = compute_cost(_, energy, axis=1)  # don't need the first argument for compute_cost\n",
    "end = time()\n",
    "\n",
    "print(\"Computing vertical cost map: %f seconds.\" % (end - start))\n",
    "\n",
    "plt.title('Vertical Cost Map')\n",
    "plt.axis('off')\n",
    "plt.imshow(vcost, cmap='inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal Cost Map\n",
    "start = time()\n",
    "hcost, _ = compute_cost(_, energy, axis=0)\n",
    "end = time()\n",
    "\n",
    "print(\"Computing horizontal cost map: %f seconds.\" % (end - start))\n",
    "\n",
    "plt.title('Horizontal Cost Map')\n",
    "plt.axis('off')\n",
    "plt.imshow(hcost, cmap='inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal seams\n",
    "\n",
    "Using the cost maps we found above, we can determine the seam with the lowest energy in the image.  \n",
    "We can then remove this optimal seam, and repeat the process until we obtain a desired width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtrack seam (5 points)\n",
    "\n",
    "Implement function `backtrack_seam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import backtrack_seam\n",
    "\n",
    "# Let's first test with a small example\n",
    "cost = np.array([[1.0, 2.0, 1.5],\n",
    "                 [4.0, 2.0, 3.5],\n",
    "                 [6.0, 2.5, 5.0]])\n",
    "\n",
    "paths = np.array([[ 0,  0,  0],\n",
    "                  [ 0, -1,  0],\n",
    "                  [ 1,  0, -1]])\n",
    "\n",
    "\n",
    "# Vertical Backtracking\n",
    "\n",
    "end = np.argmin(cost[-1])\n",
    "seam_energy = cost[-1, end]\n",
    "seam = backtrack_seam(vpaths, end)\n",
    "\n",
    "print('Seam Energy:', seam_energy)\n",
    "print('Seam:', seam)\n",
    "\n",
    "assert seam_energy == 2.5\n",
    "assert np.allclose(seam, [0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize the optimal vertical seam. The expected output is:\n",
    "\n",
    "![imgs/optimal_vertical_seam_soln.png](imgs/optimal_vertical_seam_soln.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcost, vpaths = compute_cost(img, energy)\n",
    "\n",
    "# Vertical Backtracking\n",
    "start = time()\n",
    "end = np.argmin(vcost[-1])\n",
    "seam_energy = vcost[-1, end]\n",
    "seam_ = backtrack_seam(vpaths, end)\n",
    "end = time()\n",
    "\n",
    "print(\"Backtracking optimal seam: %f seconds.\" % (end - start))\n",
    "print('Seam Energy:', seam_energy)\n",
    "\n",
    "# Visualize seam\n",
    "vseam = np.copy(img)\n",
    "for row in range(vseam.shape[0]):\n",
    "    vseam[row, seam_[row], :] = np.array([1.0, 0, 0])\n",
    "\n",
    "plt.title('Vertical Seam')\n",
    "plt.axis('off')\n",
    "plt.imshow(vseam)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, the optimal vertical seam (minimal cost) goes through the portion of sky without any cloud, which yields the lowest energy.\n",
    "\n",
    "---\n",
    "\n",
    "### Reduce (25 points)\n",
    "\n",
    "We can now use the function `backtrack` and `remove_seam` iteratively to reduce the size of the image through **seam carving**.\n",
    "\n",
    "Each reduce can take around 10 seconds to compute, depending on your implementation.\n",
    "If it's too long, try to vectorize your code in `compute_cost` to only use one loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import reduce\n",
    "\n",
    "# Let's first test with a small example\n",
    "test_img = np.arange(9, dtype=np.float64).reshape((3, 3))\n",
    "test_img = np.stack([test_img, test_img, test_img], axis=2)\n",
    "assert test_img.shape == (3, 3, 3)\n",
    "\n",
    "cost = np.array([[1.0, 2.0, 1.5],\n",
    "                 [4.0, 2.0, 3.5],\n",
    "                 [6.0, 2.5, 5.0]])\n",
    "\n",
    "paths = np.array([[ 0,  0,  0],\n",
    "                  [ 0, -1,  0],\n",
    "                  [ 1,  0, -1]])\n",
    "\n",
    "out_remove_seam = np.asarray([[[1., 1., 1.],[2., 2., 2.]],\\\n",
    "                              [[3., 3., 3.],[5., 5., 5.]],\\\n",
    "                              [[6., 6., 6.],[8., 8., 8.]]])\n",
    "\n",
    "# Reduce image width\n",
    "W_new = 2\n",
    "\n",
    "# We force the cost and paths to our values\n",
    "out = reduce(test_img, W_new, cfunc=lambda x, y: (cost, paths), bfunc=lambda x,y: seam, rfunc=lambda x,y: out_remove_seam)\n",
    "\n",
    "print(\"Original image (channel 0):\")\n",
    "print(test_img[:, :, 0])\n",
    "print(\"Reduced image (channel 0): we see that seam [0, 4, 7] is removed\")\n",
    "print(out[:, :, 0])\n",
    "\n",
    "assert np.allclose(out[:, :, 0], np.array([[1, 2], [3, 5], [6, 8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize resizing the width from 600 to 400. The expected output is:\n",
    "\n",
    "![imgs/resize_width_400.png](imgs/resize_width_400.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce image width\n",
    "H, W, _ = img.shape\n",
    "W_new = 400\n",
    "\n",
    "start = time()\n",
    "out = reduce(img, W_new)\n",
    "end = time()\n",
    "\n",
    "print(\"Reducing width from %d to %d: %f seconds.\" % (W, W_new, end - start))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Resized')\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that resizing from width 640 to width 400 conserves almost all the important part of the image (the person and the castle), where a standard resizing would have compressed everything.\n",
    "\n",
    "All the vertical seams removed avoid the person and the castle.\n",
    "\n",
    "#### Now, we can visualize resizing the height from 434 to 300. The expected output is:\n",
    "\n",
    "![imgs/resize_height_300.png](imgs/resize_height_300.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reduce image height\n",
    "H, W, _ = img.shape\n",
    "H_new = 300\n",
    "\n",
    "start = time()\n",
    "out = reduce(img, H_new, axis=0)\n",
    "end = time()\n",
    "\n",
    "print(\"Reducing height from %d to %d: %f seconds.\" % (H, H_new, end - start))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Resized')\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reducing the height, we observe that the result does not look as nice.\n",
    "\n",
    "The issue here is that the castle is on all the height of the image, so most horizontal seams will go through it.  \n",
    "Interestingly, we observe that most of the grass is not removed. This is because the grass has small variation between neighboring pixels (in a kind of noisy pattern) that make it high energy.  \n",
    "The seams removed go through the sky on the left, go under the castle to remove some grass and then back up in the low energy blue sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Enlarging\n",
    "\n",
    "### Enlarge naive (10 points)\n",
    "We now want to tackle the reverse problem of enlarging an image.  \n",
    "One naive way to approach the problem would be to duplicate the optimal seam iteratively until we reach the desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import enlarge_naive\n",
    "\n",
    "# Let's first test with a small example\n",
    "test_img = np.arange(9, dtype=np.float64).reshape((3, 3))\n",
    "test_img = np.stack([test_img, test_img, test_img], axis=2)\n",
    "assert test_img.shape == (3, 3, 3)\n",
    "\n",
    "cost = np.array([[1.0, 2.0, 1.5],\n",
    "                 [4.0, 2.0, 3.5],\n",
    "                 [6.0, 2.5, 5.0]])\n",
    "\n",
    "paths = np.array([[ 0,  0,  0],\n",
    "                  [ 0, -1,  0],\n",
    "                  [ 1,  0, -1]])\n",
    "\n",
    "out_duplicate_seam = np.asarray( [[[0., 0., 0.],[0., 0., 0.],[1., 1., 1.],[2., 2., 2.]],\\\n",
    "                                  [[3., 3., 3.],[4., 4., 4.],[4., 4., 4.],[5., 5., 5.]],\\\n",
    "                                  [[6., 6., 6.],[7., 7., 7.],[7., 7., 7.],[8., 8., 8.]]])\n",
    "\n",
    "# Increase image width\n",
    "W_new = 4\n",
    "\n",
    "# We force the cost and paths to our values\n",
    "out = enlarge_naive(test_img, W_new, cfunc=lambda x, y: (cost, paths), bfunc=lambda x,y: seam , dfunc=lambda x,y:out_duplicate_seam)\n",
    "\n",
    "print(\"Original image (channel 0):\")\n",
    "print(test_img[:, :, 0])\n",
    "print(\"Enlarged image (channel 0): we see that seam [0, 4, 7] is duplicated\")\n",
    "print(out[:, :, 0])\n",
    "\n",
    "assert np.allclose(out[:, :, 0], np.array([[0, 0, 1, 2], [3, 4, 4, 5], [6, 7, 7, 8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize naively enlarging the width from 640 to 800. The expected output is:\n",
    "\n",
    "![imgs/enlarge_naive_width_800.png](imgs/enlarge_naive_width_800.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_new = 800\n",
    "\n",
    "# This is a naive implementation of image enlarging\n",
    "# which iteratively computes energy function, finds optimal seam\n",
    "# and duplicates it.\n",
    "# This process will create a stretching artifact by choosing the same seam\n",
    "start = time()\n",
    "enlarged = enlarge_naive(img, W_new)\n",
    "end = time()\n",
    "\n",
    "# Can take around 20 seconds\n",
    "print(\"Enlarging(naive) width from %d to %d: %f seconds.\" \\\n",
    "      % (W, W_new, end - start))\n",
    "\n",
    "plt.imshow(enlarged)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with `enlarge_naive` is that the same seam will be selected again and again, so this low energy seam will be the only to be duplicated.\n",
    "\n",
    "Another way to get k different seams is to apply the process we used in function `reduce`, and keeping track of the seams we delete progressively.\n",
    "The function `find_seams(image, k)` will find the top k seams for removal iteratively.\n",
    "\n",
    "The inner workings of the function are a bit tricky so we've implemented it for you, but you should go into the code and understand how it works.  \n",
    "This should also help you for the implementation of `enlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import find_seams\n",
    "\n",
    "# Alternatively, find k seams for removal and duplicate them.\n",
    "start = time()\n",
    "seams = find_seams(img, W_new - W)\n",
    "end = time()\n",
    "\n",
    "# Can take around 10 seconds\n",
    "print(\"Finding %d seams: %f seconds.\" % (W_new - W, end - start))\n",
    "\n",
    "plt.imshow(seams, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enlarge (25 points)\n",
    "\n",
    "We can see that all the seams found are different, and they avoid the castle and the person.\n",
    "\n",
    "One issue we can mention is that we cannot enlarge more than we can reduce. Because of our process, the maximum enlargement is the width of the image `W` because we first need to find `W` different seams in the image.\n",
    "\n",
    "One effect we can see on this image is that the blue sky at the right of the castle can only be enlarged x2. The concentration of seams in this area is very strong.  \n",
    "We can also note that the seams at the right of the castle have a blue color, which means they have low value and were removed in priority in the seam selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seam_carving import enlarge\n",
    "\n",
    "# Let's first test with a small example\n",
    "test_img = np.array([[0.0, 1.0, 3.0],\n",
    "                     [0.0, 1.0, 3.0],\n",
    "                     [0.0, 1.0, 3.0]])\n",
    "#test_img = np.arange(9, dtype=np.float64).reshape((3, 3))\n",
    "test_img = np.stack([test_img, test_img, test_img], axis=2)\n",
    "assert test_img.shape == (3, 3, 3)\n",
    "\n",
    "# Increase image width\n",
    "W_new = 5\n",
    "\n",
    "out_naive = enlarge_naive(test_img, W_new)\n",
    "out = enlarge(test_img, W_new)\n",
    "\n",
    "print(\"Original image (channel 0):\")\n",
    "print(test_img[:, :, 0])\n",
    "print(\"Enlarged naive image (channel 0): first seam is duplicated twice.\")\n",
    "print(out_naive[:, :, 0])\n",
    "print(\"Enlarged image (channel 0): first and second seam are each duplicated once.\")\n",
    "print(out[:, :, 0])\n",
    "\n",
    "assert np.allclose(out[:, :, 0], np.array([[0, 0, 1, 1, 3], [0, 0, 1, 1, 3], [0, 0, 1, 1, 3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize enlarging the width from 640 to 800. The expected output is:\n",
    "\n",
    "![imgs/enlarge_width_800.png](imgs/enlarge_width_800.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_new = 800\n",
    "\n",
    "start = time()\n",
    "out = enlarge(img, W_new)\n",
    "end = time()\n",
    "\n",
    "# Can take around 20 seconds\n",
    "print(\"Enlarging width from %d to %d: %f seconds.\" \\\n",
    "      % (W, W_new, end - start))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Resized')\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map of the seams for horizontal seams.\n",
    "start = time()\n",
    "seams = find_seams(img, W_new - W, axis=0)\n",
    "end = time()\n",
    "\n",
    "# Can take around 15 seconds\n",
    "print(\"Finding %d seams: %f seconds.\" % (W_new - W, end - start))\n",
    "\n",
    "plt.imshow(seams, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can visualize enlarging the height from 434 to 600. The expected output is:\n",
    "\n",
    "![imgs/enlarge_height_600.png](imgs/enlarge_height_600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_new = 600\n",
    "\n",
    "start = time()\n",
    "out = enlarge(img, H_new, axis=0)\n",
    "end = time()\n",
    "\n",
    "# Can take around 20 seconds\n",
    "print(\"Enlarging height from %d to %d: %f seconds.\" \\\n",
    "      % (H, H_new, end - start))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Resized')\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the example above, the sky above the castle has doubled in size, the grass below has doubled in size but we still can't reach a height of 600 by just doubling the sky and grass.  \n",
    "So, the algorithm then needs to enlarge the castle itself, while trying to avoid enlarging the windows for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Other experiments on the image\n",
    "\n",
    "Feel free to experiment more on this image, try different sizes to enlarge or reduce, or check what seams are chosen...\n",
    "\n",
    "Reducing by a 2x factor often leads to weird patterns.  \n",
    "Enlarging by more than 2x is impossible since we only duplicate seams. One solution is to enlarge in mutliple steps (enlarge x1.4, enlarge again x1.4...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce image width\n",
    "H, W, _ = img.shape\n",
    "W_new = 200\n",
    "\n",
    "start = time()\n",
    "out = reduce(img, W_new)\n",
    "end = time()\n",
    "\n",
    "print(\"Reducing width from %d to %d: %f seconds.\" % (W, W_new, end - start))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Resized')\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1e3effa4cda94694f58d50afb8cbafb40407c1e4df33440e9e1eeff143e0626"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
